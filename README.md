# CGAN para gera√ß√£o de mapas padr√£o com base em imagens via Satelite

Este projeto utiliza uma **Rede Advers√°ria Generativa Condicional (CGAN)** para **gerar mapas estilizados** (como mapas de ruas, topogr√°ficos ou padr√£o OpenStreetMap) **a partir de imagens de sat√©lite**. O objetivo √© explorar como modelos GAN podem aprender a converter dados visuais complexos em representa√ß√µes simplificadas e √∫teis para navega√ß√£o, an√°lise urbana e planejamento geogr√°fico.

## üåç Motiva√ß√£o

Mapas s√£o fundamentais para nossa compreens√£o do espa√ßo geogr√°fico, mas sua cria√ß√£o exige muito trabalho manual ou acesso a bancos de dados estruturados. Com a crescente disponibilidade de **imagens de sat√©lite de alta resolu√ß√£o**, surge a oportunidade de **automatizar a gera√ß√£o de mapas** com t√©cnicas de **intelig√™ncia artificial**.

Este projeto prop√µe o uso de uma CGAN para aprender a rela√ß√£o entre imagens de sat√©lite e seus respectivos mapas, permitindo a convers√£o autom√°tica com qualidade visual e sem√¢ntica.

---

## Tecnologias utilizadas

- Python 3.10+
- TensorFlow / keras
- NumPy
- Matplotlib
- Ipython

---

## Arquitetura da CGAN

A CGAN √© composta por dois m√≥dulos principais:

- **Gerador (Generator)**: Recebe uma imagem de sat√©lite + ru√≠do e tenta gerar um mapa correspondente.
- **Discriminador (Discriminator)**: Tenta distinguir entre mapas reais e mapas gerados, aprendendo a identificar falsifica√ß√µes.

A entrada condicional √© a imagem de sat√©lite, que guia o processo de gera√ß√£o. O treinamento segue o paradigma GAN cl√°ssico, com aprendizado competitivo entre os dois m√≥dulos.

---

## üóÇÔ∏è Estrutura do Projeto

o C√≥digo foi desenvolvido com jupyter, o dataset esta disponivel no link abaixo:</br>
http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/</br>
para o modelo gerador, utilizo o modelo U-net, e para o modelo discriminador, utilizo o patchGAN. ambos modelos apresentam resultados parecidos em suas respectivas fun√ß√µes.
para o treinamento e valida√ß√£o, utilizo 1096 imagens, cada imagem apresenta dois modelos de mapas, um modelo via satelite e ao lado o modelo padr√£o para compara√ß√£o:
![modelo 1](image/2.png)
![modelo 2](image/3.png)
![modelo 3](image/7.png)
